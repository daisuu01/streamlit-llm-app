# === 0. ã‚¤ãƒ³ãƒãƒ¼ãƒˆ ===
from dotenv import load_dotenv
import os
import streamlit as st
from langchain_openai import ChatOpenAI
from langchain.prompts import ChatPromptTemplate
from langchain.chains import LLMChain

# === 1. ç’°å¢ƒå¤‰æ•°è¨­å®š ===
# ãƒ­ãƒ¼ã‚«ãƒ«ç”¨: .env ãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚ã‚Œã°èª­ã¿è¾¼ã‚€
load_dotenv()

# Streamlit Cloud ç”¨: Secretsã‹ã‚‰èª­ã¿è¾¼ã‚€
if "OPENAI_API_KEY" not in os.environ or not os.environ["OPENAI_API_KEY"]:
    os.environ["OPENAI_API_KEY"] = st.secrets.get("OPENAI_API_KEY", "")

# === ãƒ‡ãƒãƒƒã‚°è¡¨ç¤ºï¼ˆã‚µã‚¤ãƒ‰ãƒãƒ¼ï¼‰ ===
st.sidebar.header("ğŸ” API Key ãƒã‚§ãƒƒã‚¯")
api_key = os.getenv("OPENAI_API_KEY", "")
if api_key.startswith("sk-"):
    st.sidebar.success("âœ… APIã‚­ãƒ¼ãŒèªè­˜ã•ã‚Œã¾ã—ãŸ")
    st.sidebar.caption(f"Key prefix: {api_key[:8]}******")
else:
    st.sidebar.error("âŒ OPENAI_API_KEY ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
    st.sidebar.caption("Secrets ã¾ãŸã¯ .env ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
    st.stop()  # APIã‚­ãƒ¼ãŒãªã„å ´åˆã¯å®Ÿè¡Œã‚’åœæ­¢

# === 2. LLMå¿œç­”é–¢æ•° ===
def get_llm_response(expert_type, user_input):
    """å°‚é–€å®¶ã‚¿ã‚¤ãƒ—ã¨å…¥åŠ›å†…å®¹ã‚’ã‚‚ã¨ã«LLMã®å›ç­”ã‚’è¿”ã™é–¢æ•°"""

    # ã‚·ã‚¹ãƒ†ãƒ ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’é¸æŠ
    if expert_type == "è‹±èªæ•™å¸«":
        system_message = "ã‚ãªãŸã¯å„ªç§€ãªè‹±èªæ•™å¸«ã§ã™ã€‚è‹±èªå­¦ç¿’è€…ã«ã‚ã‹ã‚Šã‚„ã™ãèª¬æ˜ã—ã¦ãã ã•ã„ã€‚"
    elif expert_type == "æ „é¤Šå£«":
        system_message = "ã‚ãªãŸã¯å°‚é–€çŸ¥è­˜è±Šå¯Œãªæ „é¤Šå£«ã§ã™ã€‚å¥åº·ã‚„é£Ÿäº‹ã«é–¢ã™ã‚‹è³ªå•ã«ä¸å¯§ã«ç­”ãˆã¦ãã ã•ã„ã€‚"
    else:
        system_message = "ã‚ãªãŸã¯è¦ªåˆ‡ãªAIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚è³ªå•ã«ä¸å¯§ã«ç­”ãˆã¦ãã ã•ã„ã€‚"

    # LLMè¨­å®šï¼ˆLangChain + OpenAIï¼‰
    llm = ChatOpenAI(model="gpt-3.5-turbo", temperature=0.5)
    prompt = ChatPromptTemplate.from_messages([
        ("system", system_message),
        ("human", "{question}")
    ])
    chain = LLMChain(llm=llm, prompt=prompt)
    result = chain.run({"question": user_input})
    return result


# === 3. Streamlit UI ===
st.title("ğŸ’¬ LangChain Ã— Streamlit ãƒ‡ãƒ¢ã‚¢ãƒ—ãƒª")
st.write("""
### ğŸ§­ ã‚¢ãƒ—ãƒªæ¦‚è¦
ã“ã®ã‚¢ãƒ—ãƒªã§ã¯ã€é¸æŠã—ãŸå°‚é–€å®¶ï¼ˆè‹±èªæ•™å¸« or æ „é¤Šå£«ï¼‰ã¨ã—ã¦AIãŒå›ç­”ã—ã¾ã™ã€‚

### ğŸª„ æ“ä½œæ‰‹é †
1. å°‚é–€å®¶ã‚¿ã‚¤ãƒ—ã‚’é¸æŠ  
2. ãƒ†ã‚­ã‚¹ãƒˆã‚’å…¥åŠ›  
3. ã€Œé€ä¿¡ã€ãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯ï¼
""")

# å°‚é–€å®¶ã‚¿ã‚¤ãƒ—é¸æŠ
expert_type = st.radio("AIã®å°‚é–€å®¶ã‚¿ã‚¤ãƒ—ã‚’é¸ã‚“ã§ãã ã•ã„ï¼š", ["è‹±èªæ•™å¸«", "æ „é¤Šå£«"])

# è³ªå•å…¥åŠ›
user_input = st.text_area("è³ªå•ã‚„ç›¸è«‡å†…å®¹ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ï¼š")

# å®Ÿè¡Œãƒœã‚¿ãƒ³
if st.button("é€ä¿¡"):
    if user_input.strip():
        with st.spinner("AIãŒè€ƒãˆã¦ã„ã¾ã™..."):
            answer = get_llm_response(expert_type, user_input)
        st.success("AIã®å›ç­”ï¼š")
        st.write(answer)
    else:
        st.warning("ãƒ†ã‚­ã‚¹ãƒˆã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")

from dotenv import load_dotenv
import os
import streamlit as st
from langchain_openai import ChatOpenAI
from langchain.prompts import ChatPromptTemplate
from langchain.chains import LLMChain

load_dotenv()
if "OPENAI_API_KEY" not in os.environ or not os.environ["OPENAI_API_KEY"]:
    os.environ["OPENAI_API_KEY"] = st.secrets.get("OPENAI_API_KEY", "")

api_key = os.getenv("OPENAI_API_KEY", "")
if not api_key or not api_key.startswith("sk-"):
    st.error("OPENAI_API_KEY ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚Secrets ã¾ãŸã¯ .env ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
    st.stop()

def get_llm_response(expert_type, user_input):
    if expert_type == "è‹±èªæ•™å¸«":
        system_message = "ã‚ãªãŸã¯å„ªç§€ãªè‹±èªæ•™å¸«ã§ã™ã€‚è‹±èªå­¦ç¿’è€…ã«ã‚ã‹ã‚Šã‚„ã™ãèª¬æ˜ã—ã¦ãã ã•ã„ã€‚"
    elif expert_type == "æ „é¤Šå£«":
        system_message = "ã‚ãªãŸã¯å°‚é–€çŸ¥è­˜è±Šå¯Œãªæ „é¤Šå£«ã§ã™ã€‚å¥åº·ã‚„é£Ÿäº‹ã«é–¢ã™ã‚‹è³ªå•ã«ä¸å¯§ã«ç­”ãˆã¦ãã ã•ã„ã€‚"
    else:
        system_message = "ã‚ãªãŸã¯è¦ªåˆ‡ãªAIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚è³ªå•ã«ä¸å¯§ã«ç­”ãˆã¦ãã ã•ã„ã€‚"
    llm = ChatOpenAI(model="gpt-3.5-turbo", temperature=0.5)
    prompt = ChatPromptTemplate.from_messages([
        ("system", system_message),
        ("human", "{question}")
    ])
    chain = LLMChain(llm=llm, prompt=prompt)
    return chain.run({"question": user_input})

st.title("ğŸ’¬ LangChain Ã— Streamlit ãƒ‡ãƒ¢ã‚¢ãƒ—ãƒª")
st.write("é¸æŠã—ãŸå°‚é–€å®¶ï¼ˆè‹±èªæ•™å¸« or æ „é¤Šå£«ï¼‰ã¨ã—ã¦AIãŒå›ç­”ã—ã¾ã™ã€‚")

expert_type = st.radio("AIã®å°‚é–€å®¶ã‚¿ã‚¤ãƒ—ã‚’é¸ã‚“ã§ãã ã•ã„ï¼š", ["è‹±èªæ•™å¸«", "æ „é¤Šå£«"])
user_input = st.text_area("è³ªå•ã‚„ç›¸è«‡å†…å®¹ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ï¼š")

if st.button("é€ä¿¡"):
    if user_input.strip():
        with st.spinner("AIãŒè€ƒãˆã¦ã„ã¾ã™..."):
            answer = get_llm_response(expert_type, user_input)
        st.success("AIã®å›ç­”ï¼š")
        st.write(answer)
    else:
        st.warning("ãƒ†ã‚­ã‚¹ãƒˆã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
